{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook: Random Forest Model Training for Stock Price Prediction\n",
    "\n",
    "Introduction\n",
    "\n",
    "This notebook trains and saves Random Forest models for predicting stock prices, focusing on individual tickers.\n",
    "\n",
    "Key Steps\n",
    "\n",
    "1.\tLoad processed data from SQLite.\n",
    "\n",
    "2.\tFilter data for a specific ticker (default: XOM).\n",
    "\n",
    "3.\tPreprocess and normalize features.\n",
    "\n",
    "4.\tTrain a Random Forest model.\n",
    "\n",
    "5.\tSave the trained model and scaler for future evaluation and predictions.\n",
    "\n",
    "Import Libraries\n",
    "\n",
    "•\tpandas: For data manipulation and analysis.\n",
    "\n",
    "•\tsqlite3: For interacting with the SQLite database storing stock data.\n",
    "\n",
    "•\tscikit-learn:\n",
    "\n",
    "•\tRandomForestRegressor for training the Random Forest model.\n",
    "\n",
    "•\ttrain_test_split for splitting data.\n",
    "\n",
    "•\tStandardScaler for feature normalization.\n",
    "\n",
    "•\tmean_squared_error, r2_score for evaluating model performance.\n",
    "\n",
    "•\tjoblib: For saving trained models and scalers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model Training Notebook\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load Data from SQLite Database\n",
    "\n",
    "•\tPurpose: Load preprocessed stock data stored in the SQLite database (stocks_data.db).\n",
    "•\tSteps:\n",
    "\n",
    "1.\tDefine the database path.\n",
    "\n",
    "2.\tQuery the processed_stocks table to fetch the entire dataset.\n",
    "\n",
    "3.\tLoad the data into a pandas DataFrame.\n",
    "\n",
    "•\tOutput: Displays the number of rows loaded from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded processed data: 67834 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Load Data from SQLite Database\n",
    "db_path = 'database/stocks_data.db'\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    query = \"SELECT * FROM processed_stocks\"\n",
    "    data = pd.read_sql(query, conn)\n",
    "print(f\"Loaded processed data: {data.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Filter Data for Default Ticker\n",
    "\n",
    "•\tPurpose: Focus on a specific stock ticker for model training.\n",
    "\n",
    "•\tSteps:\n",
    "\n",
    "1.\tDefine the default ticker (e.g., XOM for Exxon Mobil).\n",
    "\n",
    "2.\tFilter the dataset to include only rows corresponding to the selected ticker.\n",
    "\n",
    "•\tOutput: Displays the number of rows for the selected ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data for XOM: 11791 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Filter Data for Default Ticker\n",
    "default_ticker = 'XOM'\n",
    "ticker_data = data[data['Ticker'] == default_ticker]\n",
    "print(f\"Loaded data for {default_ticker}: {ticker_data.shape[0]} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Define Features and Target\n",
    "\n",
    "•\tFeatures (X): Independent variables used for predictions:\n",
    "\n",
    "•\t7-day MA, 14-day MA, Volatility, Lag_1, Lag_2.\n",
    "\n",
    "•\tTarget (y): Dependent variable to predict (Adj Close - Adjusted Closing Price)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Define Features and Target\n",
    "features = ['7-day MA', '14-day MA', 'Volatility', 'Lag_1', 'Lag_2']\n",
    "target = 'Adj Close'\n",
    "X = ticker_data[features]\n",
    "y = ticker_data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Split Data into Training and Testing Sets\n",
    "\n",
    "•\tPurpose: Divide the dataset into:\n",
    "\n",
    "•\tTraining Set (80%): Used to train the model.\n",
    "\n",
    "•\tTesting Set (20%): Used to evaluate model performance.\n",
    "\n",
    "•\tOutput: Ensures fair evaluation of the model’s predictive ability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Split Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Normalize Features\n",
    "\n",
    "•\tPurpose: Normalize feature values to ensure consistency and improve model performance.\n",
    "\n",
    "•\tSteps:\n",
    "\n",
    "1.\tUse StandardScaler to scale features to zero mean and unit variance.\n",
    "\n",
    "2.\tFit the scaler to the training data.\n",
    "\n",
    "3.\tTransform both training and testing datasets using the scaler.\n",
    "\n",
    "•\tOutput: Scaled training and testing feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 5: Normalize Features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Train Random Forest Regressor\n",
    "\n",
    "•\tPurpose: Train a Random Forest model using the normalized training dataset.\n",
    "•\tSteps:\n",
    "\n",
    "1.\tInitialize the RandomForestRegressor with 100 estimators and a random seed for reproducibility.\n",
    "\n",
    "2.\tTrain the model on the scaled training data.\n",
    "\n",
    "•\tOutput: Confirms successful model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model trained successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 6: Train Random Forest Regressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"Random Forest model trained successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Evaluate Model on Test Data\n",
    "\n",
    "•\tPurpose: Assess the model’s performance on the test dataset using:\n",
    "\n",
    "1.\tMean Squared Error (MSE): Average squared prediction errors.\n",
    "\n",
    "2.\tR-squared (R²): Proportion of variance explained by the model.\n",
    "\n",
    "•\tOutput: Displays key evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation: MSE=0.24, R²=1.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 7: Evaluate Model on Test Data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Model Evaluation: MSE={mse:.2f}, R²={r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8: Save the Model and Scaler\n",
    "\n",
    "•\tPurpose: Save the trained model and scaler for future use.\n",
    "\n",
    "•\tSteps:\n",
    "\n",
    "1.\tSave the model as model_<ticker>_rf.pkl.\n",
    "\n",
    "2.\tSave the scaler as scaler_<ticker>_rf.pkl.\n",
    "\n",
    "•\tOutput: Confirms successful saving of the model and scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'models/model_XOM_rf.pkl' and scaler saved as 'models/scaler_XOM_rf.pkl'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 8: Save the Model and Scaler\n",
    "model_filename = f'models/model_{default_ticker}_rf.pkl'\n",
    "scaler_filename = f'models/scaler_{default_ticker}_rf.pkl'\n",
    "joblib.dump(model, model_filename)\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "print(f\"Model saved as '{model_filename}' and scaler saved as '{scaler_filename}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary\n",
    "\n",
    "This notebook successfully trains a Random Forest model for the default ticker (XOM) by:\n",
    "\n",
    "1.\tLoading preprocessed data.\n",
    "\n",
    "2.\tFiltering data for the selected ticker.\n",
    "\n",
    "3.\tNormalizing features and splitting the dataset.\n",
    "\n",
    "4.\tTraining the Random Forest model.\n",
    "\n",
    "5.\tSaving the trained model and scaler for evaluation and predictions.\n",
    "\n",
    "Next Steps\n",
    "\n",
    "1.\tEvaluate model predictions using a separate evaluation notebook.\n",
    "\n",
    "2.\tExtend the Flask app to dynamically load and use the saved Random Forest model.\n",
    "\n",
    "3.\tVisualize the model’s predictions and residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
