{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Data Preprocessing\n",
    "This notebook performs the following tasks:\n",
    "1. Loads raw stock data from the SQLite database.\n",
    "2. Cleans and filters the data for inconsistencies and missing values.\n",
    "3. Engineers new features to enrich the dataset for machine learning.\n",
    "4. Stores the processed data back into the SQLite database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries\n",
    "Libraries used:\n",
    "- `pandas`: For data manipulation and cleaning.\n",
    "- `numpy`: For numerical operations.\n",
    "- `sqlite3`: For database interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Raw Stock Data\n",
    "Loads the raw stock data from the SQLite database (`stocks_data.db`) using SQL queries. The data is retrieved from the `stocks` table created in Notebook 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from SQLite: 71624 rows\n"
     ]
    }
   ],
   "source": [
    "# Path to SQLite database\n",
    "db_path = 'database/stocks_data.db'\n",
    "\n",
    "# Step 1: Load raw stock data from SQLite\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    query = \"SELECT * FROM stocks\"\n",
    "    raw_data = pd.read_sql(query, conn)\n",
    "\n",
    "print(f\"Loaded data from SQLite: {raw_data.shape[0]} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Validating Data\n",
    "Steps taken to ensure data quality:\n",
    "- Converts the `Adj Close` column to numeric format to handle any non-numeric values.\n",
    "- Drops rows with missing values in the `Adj Close` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Adj Close' is numeric\n",
    "raw_data['Adj Close'] = pd.to_numeric(raw_data['Adj Close'], errors='coerce')\n",
    "raw_data = raw_data.dropna(subset=['Adj Close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "New features are added to improve the dataset for machine learning:\n",
    "1. **Moving Averages**:\n",
    "   - `7-day MA`: 7-day rolling average of adjusted close prices.\n",
    "   - `14-day MA`: 14-day rolling average of adjusted close prices.\n",
    "2. **Volatility**:\n",
    "   - Standard deviation of daily percentage changes over a 7-day rolling window.\n",
    "3. **Lagged Prices**:\n",
    "   - `Lag_1`: Previous day's adjusted close price.\n",
    "   - `Lag_2`: Adjusted close price from two days prior.\n",
    "\n",
    "Missing values resulting from rolling windows and lags are dropped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Engineer Features\n",
    "# 2.1 Moving Averages\n",
    "raw_data['7-day MA'] = raw_data.groupby('Ticker')['Adj Close'].transform(lambda x: x.rolling(window=7).mean())\n",
    "raw_data['14-day MA'] = raw_data.groupby('Ticker')['Adj Close'].transform(lambda x: x.rolling(window=14).mean())\n",
    "\n",
    "# 2.2 Volatility (7-day rolling standard deviation of percentage changes)\n",
    "raw_data['Daily Return'] = raw_data.groupby('Ticker')['Adj Close'].pct_change()  # Daily percentage changes\n",
    "raw_data['Volatility'] = raw_data.groupby('Ticker')['Daily Return'].transform(lambda x: x.rolling(window=7).std())\n",
    "\n",
    "# 2.3 Lagged Prices\n",
    "raw_data['Lag_1'] = raw_data.groupby('Ticker')['Adj Close'].shift(1)\n",
    "raw_data['Lag_2'] = raw_data.groupby('Ticker')['Adj Close'].shift(2)\n",
    "\n",
    "# Drop rows with NaN values caused by rolling/lags\n",
    "processed_data = raw_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Processed Data\n",
    "The cleaned and enriched dataset is saved back to the SQLite database in a new table: `processed_stocks`. This allows seamless integration with the next stage (machine learning).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to SQLite database (table: 'processed_stocks').\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Save processed data back to SQLite\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    processed_data.to_sql('processed_stocks', conn, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Processed data saved to SQLite database (table: 'processed_stocks').\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying Processed Data\n",
    "Displays a preview of the processed dataset to confirm:\n",
    "- The presence of newly engineered features.\n",
    "- The absence of missing or invalid data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Date  Adj Close     Close      High       Low      Open  \\\n",
      "13  2000-01-21 00:00:00  19.416449  42.50000  42.59375  41.65625  42.00000   \n",
      "14  2000-01-24 00:00:00  19.245121  42.12500  43.15625  41.50000  42.71875   \n",
      "15  2000-01-25 00:00:00  19.202299  42.03125  43.06250  41.90625  42.00000   \n",
      "16  2000-01-26 00:00:00  19.073801  41.75000  42.28125  41.34375  42.03125   \n",
      "17  2000-01-27 00:00:00  18.502726  40.50000  41.65625  39.87500  41.65625   \n",
      "\n",
      "      Volume      Company Ticker   7-day MA  14-day MA  Daily Return  \\\n",
      "13  14343600  Exxon Mobil    XOM  19.308347  19.019752      0.015684   \n",
      "14  12459400  Exxon Mobil    XOM  19.332822  19.116630     -0.008824   \n",
      "15  11921600  Exxon Mobil    XOM  19.287952  19.234925     -0.002225   \n",
      "16   9298000  Exxon Mobil    XOM  19.279794  19.275716     -0.006692   \n",
      "17  10548400  Exxon Mobil    XOM  19.157421  19.207391     -0.029940   \n",
      "\n",
      "    Volatility      Lag_1      Lag_2  \n",
      "13    0.017801  19.116625  19.544924  \n",
      "14    0.018042  19.416449  19.116625  \n",
      "15    0.015271  19.245121  19.416449  \n",
      "16    0.013462  19.202299  19.245121  \n",
      "17    0.016132  19.073801  19.202299  \n"
     ]
    }
   ],
   "source": [
    "# Check the processed data\n",
    "print(processed_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
