{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Data Preprocessing\n",
    "This notebook performs the following tasks:\n",
    "1. Loads raw stock data from the SQLite database.\n",
    "2. Cleans and filters the data for inconsistencies and missing values.\n",
    "3. Engineers new features to enrich the dataset for machine learning.\n",
    "4. Stores the processed data back into the SQLite database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries\n",
    "Libraries used:\n",
    "- `pandas`: For data manipulation and cleaning.\n",
    "- `numpy`: For numerical operations.\n",
    "- `sqlite3`: For database interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Raw Stock Data\n",
    "Loads the raw stock data from the SQLite database (`stocks_data.db`) using SQL queries. The data is retrieved from the `stocks` table created in Notebook 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from SQLite: 34570 rows\n"
     ]
    }
   ],
   "source": [
    "# Path to SQLite database\n",
    "db_path = 'database/stocks_data.db'\n",
    "\n",
    "# Step 1: Load raw stock data from SQLite\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    query = \"SELECT * FROM stocks\"\n",
    "    raw_data = pd.read_sql(query, conn)\n",
    "\n",
    "print(f\"Loaded data from SQLite: {raw_data.shape[0]} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Validating Data\n",
    "Steps taken to ensure data quality:\n",
    "- Converts the `Adj Close` column to numeric format to handle any non-numeric values.\n",
    "- Drops rows with missing values in the `Adj Close` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Adj Close' is numeric\n",
    "raw_data['Adj Close'] = pd.to_numeric(raw_data['Adj Close'], errors='coerce')\n",
    "raw_data = raw_data.dropna(subset=['Adj Close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "New features are added to improve the dataset for machine learning:\n",
    "1. **Moving Averages**:\n",
    "   - `7-day MA`: 7-day rolling average of adjusted close prices.\n",
    "   - `14-day MA`: 14-day rolling average of adjusted close prices.\n",
    "2. **Volatility**:\n",
    "   - Standard deviation of daily percentage changes over a 7-day rolling window.\n",
    "3. **Lagged Prices**:\n",
    "   - `Lag_1`: Previous day's adjusted close price.\n",
    "   - `Lag_2`: Adjusted close price from two days prior.\n",
    "\n",
    "Missing values resulting from rolling windows and lags are dropped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Engineer Features\n",
    "# 2.1 Moving Averages\n",
    "raw_data['7-day MA'] = raw_data.groupby('Ticker')['Adj Close'].transform(lambda x: x.rolling(window=7).mean())\n",
    "raw_data['14-day MA'] = raw_data.groupby('Ticker')['Adj Close'].transform(lambda x: x.rolling(window=14).mean())\n",
    "\n",
    "# 2.2 Volatility (7-day rolling standard deviation of percentage changes)\n",
    "raw_data['Daily Return'] = raw_data.groupby('Ticker')['Adj Close'].pct_change()  # Daily percentage changes\n",
    "raw_data['Volatility'] = raw_data.groupby('Ticker')['Daily Return'].transform(lambda x: x.rolling(window=7).std())\n",
    "\n",
    "# 2.3 Lagged Prices\n",
    "raw_data['Lag_1'] = raw_data.groupby('Ticker')['Adj Close'].shift(1)\n",
    "raw_data['Lag_2'] = raw_data.groupby('Ticker')['Adj Close'].shift(2)\n",
    "\n",
    "# Drop rows with NaN values caused by rolling/lags\n",
    "processed_data = raw_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Processed Data\n",
    "The cleaned and enriched dataset is saved back to the SQLite database in a new table: `processed_stocks`. This allows seamless integration with the next stage (machine learning).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to SQLite database (table: 'processed_stocks').\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Save processed data back to SQLite\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    processed_data.to_sql('processed_stocks', conn, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Processed data saved to SQLite database (table: 'processed_stocks').\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying Processed Data\n",
    "Displays a preview of the processed dataset to confirm:\n",
    "- The presence of newly engineered features.\n",
    "- The absence of missing or invalid data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Date  Adj Close     Close      High       Low      Open  \\\n",
      "13  2001-01-22 00:00:00  18.726229  40.12500  40.31250  39.62500  39.87500   \n",
      "14  2001-01-23 00:00:00  19.090828  40.90625  40.96875  40.06250  40.25000   \n",
      "15  2001-01-24 00:00:00  19.047083  40.81250  41.25000  40.50000  41.12500   \n",
      "16  2001-01-25 00:00:00  19.251263  41.25000  41.40625  41.00000  41.15625   \n",
      "17  2001-01-26 00:00:00  18.901243  40.50000  41.28125  40.34375  41.25000   \n",
      "\n",
      "      Volume      Company Ticker   7-day MA  14-day MA  Daily Return  \\\n",
      "13  13861600  Exxon Mobil    XOM  18.849152  19.198133      0.010228   \n",
      "14  11131600  Exxon Mobil    XOM  18.851235  19.076250      0.019470   \n",
      "15  12859800  Exxon Mobil    XOM  18.811649  19.015830     -0.002291   \n",
      "16  13595000  Exxon Mobil    XOM  18.834568  19.009580      0.010720   \n",
      "17  11860000  Exxon Mobil    XOM  18.859570  18.972077     -0.018182   \n",
      "\n",
      "    Volatility      Lag_1      Lag_2  \n",
      "13    0.013360  18.536636  18.463711  \n",
      "14    0.015138  18.726229  18.536636  \n",
      "15    0.014049  19.090828  18.726229  \n",
      "16    0.013960  19.047083  19.090828  \n",
      "17    0.013739  19.251263  19.047083  \n"
     ]
    }
   ],
   "source": [
    "# Check the processed data\n",
    "print(processed_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
