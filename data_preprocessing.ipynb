{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Data Preprocessing\n",
    "This notebook performs the following tasks:\n",
    "1. Loads raw stock data from the SQLite database.\n",
    "2. Cleans and filters the data for inconsistencies and missing values.\n",
    "3. Engineers new features to enrich the dataset for machine learning.\n",
    "4. Stores the processed data back into the SQLite database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries\n",
    "Libraries used:\n",
    "- `pandas`: For data manipulation and cleaning.\n",
    "- `numpy`: For numerical operations.\n",
    "- `sqlite3`: For database interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Raw Stock Data\n",
    "Loads the raw stock data from the SQLite database (`stocks_data.db`) using SQL queries. The data is retrieved from the `stocks` table created in Notebook 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from SQLite: 24168 rows\n"
     ]
    }
   ],
   "source": [
    "# Path to SQLite database\n",
    "db_path = 'database/stocks_data.db'\n",
    "\n",
    "# Step 1: Load raw stock data from SQLite\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    query = \"SELECT * FROM stocks\"\n",
    "    raw_data = pd.read_sql(query, conn)\n",
    "\n",
    "print(f\"Loaded data from SQLite: {raw_data.shape[0]} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Validating Data\n",
    "Steps taken to ensure data quality:\n",
    "- Converts the `Adj Close` column to numeric format to handle any non-numeric values.\n",
    "- Drops rows with missing values in the `Adj Close` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Adj Close' is numeric\n",
    "raw_data['Adj Close'] = pd.to_numeric(raw_data['Adj Close'], errors='coerce')\n",
    "raw_data = raw_data.dropna(subset=['Adj Close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "New features are added to improve the dataset for machine learning:\n",
    "1. **Moving Averages**:\n",
    "   - `7-day MA`: 7-day rolling average of adjusted close prices.\n",
    "   - `14-day MA`: 14-day rolling average of adjusted close prices.\n",
    "2. **Volatility**:\n",
    "   - Standard deviation of daily percentage changes over a 7-day rolling window.\n",
    "3. **Lagged Prices**:\n",
    "   - `Lag_1`: Previous day's adjusted close price.\n",
    "   - `Lag_2`: Adjusted close price from two days prior.\n",
    "\n",
    "Missing values resulting from rolling windows and lags are dropped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Engineer Features\n",
    "# 2.1 Moving Averages\n",
    "raw_data['7-day MA'] = raw_data.groupby('Ticker')['Adj Close'].transform(lambda x: x.rolling(window=7).mean())\n",
    "raw_data['14-day MA'] = raw_data.groupby('Ticker')['Adj Close'].transform(lambda x: x.rolling(window=14).mean())\n",
    "\n",
    "# 2.2 Volatility (7-day rolling standard deviation of percentage changes)\n",
    "raw_data['Daily Return'] = raw_data.groupby('Ticker')['Adj Close'].pct_change()  # Daily percentage changes\n",
    "raw_data['Volatility'] = raw_data.groupby('Ticker')['Daily Return'].transform(lambda x: x.rolling(window=7).std())\n",
    "\n",
    "# 2.3 Lagged Prices\n",
    "raw_data['Lag_1'] = raw_data.groupby('Ticker')['Adj Close'].shift(1)\n",
    "raw_data['Lag_2'] = raw_data.groupby('Ticker')['Adj Close'].shift(2)\n",
    "\n",
    "# Drop rows with NaN values caused by rolling/lags\n",
    "processed_data = raw_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Processed Data\n",
    "The cleaned and enriched dataset is saved back to the SQLite database in a new table: `processed_stocks`. This allows seamless integration with the next stage (machine learning).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to SQLite database (table: 'processed_stocks').\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Save processed data back to SQLite\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    processed_data.to_sql('processed_stocks', conn, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Processed data saved to SQLite database (table: 'processed_stocks').\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying Processed Data\n",
    "Displays a preview of the processed dataset to confirm:\n",
    "- The presence of newly engineered features.\n",
    "- The absence of missing or invalid data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Date  Adj Close      Close       High        Low  \\\n",
      "13  2015-01-22 00:00:00  60.068405  92.870003  92.970001  91.320000   \n",
      "14  2015-01-23 00:00:00  58.787758  90.889999  92.480003  90.790001   \n",
      "15  2015-01-26 00:00:00  59.350445  91.760002  91.940002  90.470001   \n",
      "16  2015-01-27 00:00:00  58.826534  90.949997  91.599998  90.599998   \n",
      "17  2015-01-28 00:00:00  56.886143  87.949997  90.930000  87.820000   \n",
      "\n",
      "         Open    Volume      Company Ticker   7-day MA  14-day MA  \\\n",
      "13  92.309998  13559000  Exxon Mobil    XOM  58.734148  58.857040   \n",
      "14  92.279999  14706300  Exxon Mobil    XOM  58.816386  58.767414   \n",
      "15  90.610001  10672500  Exxon Mobil    XOM  59.003032  58.835326   \n",
      "16  91.239998  12301500  Exxon Mobil    XOM  59.186907  58.887994   \n",
      "17  90.879997  17829700  Exxon Mobil    XOM  58.893997  58.760021   \n",
      "\n",
      "    Daily Return  Volatility      Lag_1      Lag_2  \n",
      "13      0.010885    0.011294  59.421597  58.917099  \n",
      "14     -0.021320    0.014743  60.068405  59.421597  \n",
      "15      0.009571    0.014877  58.787758  60.068405  \n",
      "16     -0.008827    0.014895  59.350445  58.787758  \n",
      "17     -0.032985    0.017003  58.826534  59.350445  \n"
     ]
    }
   ],
   "source": [
    "# Check the processed data\n",
    "print(processed_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
